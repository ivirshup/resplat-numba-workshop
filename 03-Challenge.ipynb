{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you'll be trying to visualize the seperation of text documents based on their contents. To do this, you'll build a graph where each node is a document, and has edges connecting to all other nodes weighted by their similarity. This is computationally expensive for a couple reasons. The first is that you're computing pairwise distances. This is something which can easily enought to do with numba, here's an example for calculating pairwise euclidean distances for an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups, make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_x, blobs_y = make_blobs(n_samples=100, n_features=10, centers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def pairwise(X, metric: \"Callable\"):\n",
    "    dists = np.zeros((X.shape[0], X.shape[0]), dtype=np.float64)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(i+1, X.shape[0]):\n",
    "            dists[i, j] = metric(X[i, :], X[j, :])\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def euclidean_dist(a, b):\n",
    "    return np.sum((a - b) ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time d = pairwise(blobs_x, euclidean_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, both scipy and scikit-learn already have fast implementations for pairwise distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import scipy.spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sklearn.metrics.pairwise_distances(blobs_x, metric=\"euclidean\")\n",
    "%timeit scipy.spatial.distance.pdist(blobs_x, metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why do we need numba?\n",
    "\n",
    "Well, text data is often represented as a matrix where the rows are documents and the columns are words. Since there are a lot of words used in a corpus, but not every document uses every word this matrix tends to have a lot of zeros. Another way to say this is that it's sparse. There are efficient representations for [sparse matrices](https://en.wikipedia.org/wiki/Sparse_matrix) included in scipy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [COO (COOrdinate) format](https://en.wikipedia.org/wiki/Sparse_matrix#Coordinate_list_(COO)) (`scipy.sparse.coo_matrix`)\n",
    "\n",
    "Given a dense array like:\n",
    "\n",
    "```\n",
    "0 0 1 1 0\n",
    "0 2 0 0 0\n",
    "0 0 0 3 4\n",
    "```\n",
    "\n",
    "The coo sparse format stores the coordinates for each value and the value itself in three equal length arrays. The previous matrix would look like:\n",
    "\n",
    "```\n",
    "row  col  data\n",
    "---  ---  ----\n",
    "0    2    1\n",
    "0    3    1\n",
    "1    1    2\n",
    "2    3    3\n",
    "2    4    4\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## [CSR (Compressed Sparse Row) format](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format)) (`scipy.sparse.csr_matrix`)\n",
    "\n",
    "CSR format is similar to COO, except we've \"compressed\" the data along the rows. This replaces the row array with `indptr`, which instead of repeating the row number, just tells you ranges for which values of that row are defined. The matrix above would be represented as:\n",
    "\n",
    "````\n",
    "indptr indices data\n",
    "------ ------- ----\n",
    "0      2       1\n",
    "2      3       1\n",
    "3      1       2\n",
    "5      3       3\n",
    "       4       4\n",
    "```\n",
    "\n",
    "Note that `indices` and `data` are similar to COO, but `len(indptr) == (matrix.shape[0] + 1)`.\n",
    "\n",
    "If we wanted to get all of the data points for row i, we could write:\n",
    "\n",
    "```python\n",
    "idx_slice = slice(matrix.indptr[i], matrix.indptr[i+1])\n",
    "indices_i = matrix.indices[idx_slice]\n",
    "data_i = matrix.data[idx_slice]\n",
    "```\n",
    "\n",
    "Or if we wanted to get indices for values of each row:\n",
    "\n",
    "```python\n",
    "for i in range(matrix.shape[0]):\n",
    "    indices_i = matrix.indices[matrix.indptr[i]:matrix.indptr[i+1]]\n",
    "# or\n",
    "indices_by_row = np.split(matrix.indices, matrix.indptr[1:-1])\n",
    "```\n",
    "\n",
    "`CSR` format is how scikit learn typically represents text data. Lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = make_pipeline(\n",
    "    CountVectorizer(),\n",
    "    TfidfTransformer()\n",
    ")\n",
    "\n",
    "corpus = fetch_20newsgroups(categories=['talk.religion.misc', 'comp.graphics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = preprocess.fit_transform(corpus.data).astype(bool)\n",
    "occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we've encoded documents as a boolean sparse matrix, where `occurences[i, j] = True` if document `i` contains word `j`. Now, how should we tell which documents are closer to each other?\n",
    "\n",
    "## Jaccard similarity\n",
    "\n",
    "$$ Jaccard = \\frac{|s_i \\cap s_j|}{|s_i \\cup s_j|} $$\n",
    "\n",
    "So that the total number of words which show up in each article divided by the total number of unique words which show up in both. Or:\n",
    "\n",
    "$$ Jaccard = \\frac{\\text{Number of shared words}}{\\text{Total unique words}} $$\n",
    "\n",
    "This can could be written in python like:\n",
    "\n",
    "```python\n",
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    len_intersect = a.intersection(b)\n",
    "    return len_intersect / (len(a) + len(b) - len_intersect)\n",
    "```\n",
    "\n",
    "## The problem\n",
    "\n",
    "### A.\n",
    "\n",
    "`sklearn` doesn't have a method to calculate pairwise jaccard similarities for sparse matrices. Can you modify the pairwise code and jaccard similarity function to implement this using `numba`? A key part of this problem is figuring out which objects and functions will work with `numba`, and figuring out what values to pass into jitted functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're done with this, we can use `networkx` to visualize how the groups seperate by using the similarities as edge weights on a graph, the using a force directed layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = nx.from_numpy_array(result)\n",
    "nx.draw_spring(g, node_color=corpus.target, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.\n",
    "\n",
    "The implementation I gave for jaccard similarities is inefficient in this instance, since `set.intersection` is fairly slow. There's a faster way to calculate this.\n",
    "\n",
    "*Hint*: Take advantage of the fact the csr matrix returned by sklearn has sorted indices for each row. That is:\n",
    "\n",
    "```python\n",
    "def issorted(x):\n",
    "    return np.all(np.sort(x) == x)\n",
    "assert all(map(issorted, np.split(occurences.indices, occurences.indptr[1:-1])))\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 DeJong attractors:\n",
    "\n",
    "Based on an [Observable notebook from Mike Bostock](https://observablehq.com/@mbostock/making-webgl-dance?collection=@observablehq/webgl), let's visualize some attractors, mostly because they look cool: \n",
    "\n",
    "![dejong](dejong.png)\n",
    "\n",
    "This problem is also a good example of parallelism. Notably, this problem parallelizes well on a GPU. If you have a CUDA or ROCm GPU I highly recommend you try and implement this function for that.\n",
    "\n",
    "Make a numba-ized version of this function for the DeJong attractor. Once you have it working, try making it [run in parallel by passing `parallel=True`](http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel) to `@jit`, this should give you a signifigant speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "from numpy import sin, cos\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dejong(N, a, b, c, d, it=8):\n",
    "    N = 500\n",
    "    cur = np.zeros((N, N, 2), dtype=\"f8\")\n",
    "    cur[:, :, 0] = np.arange(N)[:, None] + np.zeros(N)\n",
    "    cur[:, :, 1] = np.arange(N) + np.zeros(N)[:, None]\n",
    "    prev = np.empty_like(cur)\n",
    "    for i in range(it):\n",
    "        prev[:] = cur[:]\n",
    "        cur[:, :, 0] = sin(a * prev[:, :, 1]) - cos(b * prev[:, :, 0]) / 2\n",
    "        cur[:, :, 1] = sin(c * prev[:, :, 0]) - cos(d * prev[:, :, 1]) / 2\n",
    "    return cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dejong(100, -2, -2, 1.2, 2).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(np.histogram2d(out[:, 0], out[:, 1], 200)[0], cmap=\"Blues\", norm=colors.LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "65.29411315917969px",
    "width": "252.35293579101562px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
